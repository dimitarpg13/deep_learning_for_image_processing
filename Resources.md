# Resources on Deep Learning algorithms for Image Processing and Generative tasks

## books 

[Computer Vision: Algorithms and Applications, 2nd ed, Richard Szeliski, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/books/Computer_Vision-Algorithms_and_Applications_2nd_Edition_Richard_Szeliski_2022.pdf)

[Dive into Deep Learning, Interactive deep learning book with code, math, and discussions, Aston Zhang, Zachary Lipton, Mu Li, Alexander Smola, online version](https://d2l.ai/index.html)

[Deep Learning, Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/books/deeplearning_latest_edition.pdf)

[Understanding Deep Learning, Simon J. Prince, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/books/UnderstandingDeepLearning_13_10_23_C.pdf)

(book site URL: https://udlbook.github.io/udlbook/)

[Deep Learning for Computer Vision: Image Classification, Object Detection and Face Recognition in Python, Jason Brownlee, 2019](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/books/Deep_Learning_for_Computer_Vision-Image_Classification_Object_Detection_and_Face_Recognition_in_Python_by_Jason_Brownlee.pdf)

## articles

### Problems in Image Recongition and Machine Vision

#### Semantic Segmentation

[R-CNN: Rich Feature Hierarchies for Accurate Object Detection, Ross Girshick et al, UC Berkeley, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/semantic_segmentation/RCNN_RichFeatureHierarchiesForAccurateObjectDetection.pdf)

[Highly Accurate Dichotomous Image Segmentation, Xuebin Qin et al, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/semantic_segmentation/Highly_Accurate_Dichotomous_Image_Segmentation_Qin_2022.pdf)

#### Anomaly Detection

[Exploring EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level Latencies: A Brief Overview, Vincent Liu, Medium, 2024](https://medium.com/towards-artificial-intelligence/exploring-efficientad-accurate-visual-anomaly-detection-at-millisecond-level-latencies-a-brief-3b22b70f886b)

[Anomalib v1.0.1: Unveiling Anomaly Detection on Plastic Surfaces, Vincent Liu, Medium, 2024](https://medium.com/ai-advances/anomalib-v1-0-1-unveiling-anomaly-detection-on-plastic-surfaces-c91cd48d8806)

related repo: https://github.com/openvinotoolkit/anomalib

### Models and Neural Architectures

#### CNNs

[ImageNet Classification with Deep Convolutional Neural Nets, Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton, NIPS, 2012](https://github.com/dimitarpg13/deep_learning_for_image_processing/tree/main/literature/articles/cnn)

##### Deconstructing Convolutional Neural Networks

[Feature Visualization, Chris Olah et al, OpenAI, 2017](https://distill.pub/2017/feature-visualization/) 

[Zoom In: An Introduction to Circuits, Chris Olah et al, OpenAI, 2020](https://distill.pub/2020/circuits/zoom-in/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Zoom_In_An_Introduction_to_Circuits_Olah_OpenAI_2020.pdf)

[An Overview of Early Vision in InceptionV1, Chris Olah et al, OpenAI, 2020](https://distill.pub/2020/circuits/early-vision/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/An_Overview_of_Early_Vision_in_InceptionV1_Olah_OpenAI_2020.pdf)

[Curve Detectors, Nick Cammarata et al, OpenAI, 2020](https://distill.pub/2020/circuits/curve-detectors/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Circuits_Curve_Detectors_Olah_OpenAI_2020.pdf)

[Naturally Occurring Equivariance in Neural Networks, Chris Olah et al, OpenAI, 2020](https://distill.pub/2020/circuits/equivariance/)

[High-Low Frequency Detectors, Ludwig Schubert et al, OpenAI, 2021](https://distill.pub/2020/circuits/frequency-edges/)

[Curve Circuits, Nick Cammarata et al, OpenAI, 2021](https://distill.pub/2020/circuits/curve-circuits/)

[Visualizing Weights, Chelsea Voss et al, OpenAI, 2021](https://distill.pub/2020/circuits/visualizing-weights/)

[Branch Specialization, Chelsea Voss et al, OpenAI, 2021](https://distill.pub/2020/circuits/branch-specialization/)

[Weight Banding, Michael Petrov et al, OpenAI, 2021](https://distill.pub/2020/circuits/weight-banding/)

[Going deeper with convolutions, Christian Szegedy et al, Google, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Going_deeper_with_convolutions_Szegedy_Google_2014.pdf)

[Visualizing and Understanding Convolutional Networks, Matthew D. Zeiler et al, Courant Institute, NYU, 2013](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Visualizing_and_Understanding_Convolutional_Networks_Zeller_Courant_Institute_2013.pdf)

[Network Dissection: Quantifying Interpretability of Deep Visual Representations, David Bau et al, CSAIL MIT, 2017](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Network_Dissection-Quantifying_Interpretability_of_Deep_Visual_Representations_Bau_2017.pdf)

[Visualizing Higher Level Features of a Deep Network, Dumitru Erhan et al, Universite de Montreal, 2009](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Visualizing_Higher-Layer_Features_of_a_Deep_Network_Erhan_2009.pdf)

[Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, Karen Simonyan et al, Visual Geometry Group, U. of Oxford, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Deep_Inside_Convolutional_Networks-Visualising_Image_Classification_Models_and_Saliency_Maps_Simonyan_2014.pdf)

[Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images, Anh Nguyen et al, U. of Wyoming, 2015](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Deep_Neural_Networks_are_Easily_Fooled-High_Confidence_Predictions_for_Unrecognizable_Images_Anh_Nguyen_2015.pdf)

[What Causes Polysemanticity? An Alternative Origin Story of Mixed Selectivity from Incidental Causes, Anonymous](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/What_Causes_Polysemanticity_An_Alternative_Origin_Story_of_Mixed_Selectivity_From_Incidental_Causes.pdf)

##### Singular Neural Networks

[Why Your Neural Network is Still Singular and What You Can Do About It, Jakub Dworakowski, Pablo Rodriguez Bertorello, Stanford U., 2019](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/interpretability/Why_Your_Neural_Network_is_Still_Singular_and_What_You_Can_Do_About_It_Dworakowski_2019.pdf)

###### [Distiling Singular Learning Theory](https://www.lesswrong.com/s/czrXjvCLsqGepybHC)

[Distilling Singular Learning Theory, Liam Carroll, June 2023](https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/xRWsfGfvDAjRWXcnG)

[The RLCT Measures the Effective Dimension of Neural Networks, Liam Carroll, June 2023](https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/4eZtmwaqhAgdJQDEg)

[Why Neural Networks Obey Occam's Razor, Liam Carroll, June 2023](https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/CZHwwDd7t9aYra5HN)

[Neural Networks Are Singular, Liam Carroll, June 2023](https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/tZwaGp5wMQqKh3krz)

[Phase Transitions in Neural Networks, Liam Carroll, June 2023](https://www.lesswrong.com/s/czrXjvCLsqGepybHC/p/aKBAYN5LpaQMrPqMj)

#### Autoencoders

[Neural Networks: Unleashing the Power of Latent Space Compression by Julien Pascal, May 2023, Medium](https://medium.com/@julien.pascal/neural-networks-unleashing-the-power-of-latent-space-compression-2c8630f6f6cc)

[Autoencoders, Dor Bank, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/autoencoders/Autoencoders.pdf)

[Autoencoders, Unsupervised Learning, and Deep Architectures, Pierre Baldi, 2012](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/autoencoders/Autoencoders_Unsupervised_Learning_and_Deep_Architectures_Baldi_2012a.pdf)

[Neural Networks and Principal Component Analysis: Learning from Examples Without Local Minima, Pierre Baldi, Kurt Hornik, 1988](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/autoencoders/Neural_Networks_and_Principal_Component_Analysis-Learning_from_Examples_Without_Local_Minima_Baldi_Hornik-89.pdf)

[Neural Networks: Unleashing the Power of Latent Space Compression, Julien Pascal, Medium, 2023](https://medium.com/@julien.pascal/neural-networks-unleashing-the-power-of-latent-space-compression-2c8630f6f6cc)

[The Sparse Autoencoder, Andrew Ng, Lecture Notes CS294A](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/autoencoders/sparseAutoencoder_AndrewNg_LectureNotes.pdf)

[Tutorial On Principal Component Analysis, Jonathon Shlens, Google Research, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/autoencoders/Tutorial_on_Principal_Component_Analysis_Shlens_Google_2014.pdf)

#### LSTM, RNNs and Seq2Seq Modeling

[Long Short-Term Memory, Sepp Hochreiter et al., 1997](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/LongShortTermMemory.pdf)

[LSTM Can Solve Hard Long Time Lag Problems, Sepp Hochreiter, Juergen Schmidthhuber, NIPS, 1996](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/NIPS-1996-lstm-can-solve-hard-long-time-lag-problems-Paper_Hochreiter.pdf)

[Recurent Models of Visual Attention, Volodimir Mnih et al, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/Recurrent_Models_of_Visual_Attention_Mnih_2014.pdf)

[Sequence to Sequence Learning with Neural Networks, Sutskever et al, Google Research, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/SequencetoSequenceLearningwithNeuralNetworksSutsekver2014.pdf)

[Generating Sequences with Recurrent Neural Networks, Alex Graves, UofToronto, 2014](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/Generating_Sequences_With_Recurrent_Neural_Networks_Graves_2014.pdf)

[The Unreasonable Effectiveness of Recurrent Neural Networks, Andrej Karpathy's blog, May 2015](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/TheUnreasonableEffectivenessofRecurrentNeuralNetworksAndrejKarpathyBlog.pdf)

[Understanding LSTM: a tutorial into Long Short-Term Memory, R. Staudemeyer et al., 2019](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/TutorialOnLongShortTermMemory2019.pdf)

[A Tutorial on Training RNNs covering BPPT, RTRL, EKF, and the "echo state network" approach, Herber Jaeger, 2002](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/TutorialOnRNNAndBPTTJaeger2002.pdf)

[Understanding LSTM: Colah's Blog, 2015](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/lstm_and_rnn/UnderstandingLSTMNetworks-colahsblog.pdf)

#### Transformers

[A Mathematical Framework for Transformer Circuits, Nelson Elhage et al, Anthropic, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/A_Mathematical_Framework_for_Transformer_Circuits_Elhage_Anthropic_2021.pdf)

[An Image is Worth 16X16 Wwords: Transformers for Image Recognition at Scale, A. Dosovitskiy, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/An_Image_is_Worth_16X16_words-Transformers_for_Image_Recognition_at_Scale_Dosovitskiy_2021.pdf)

[Attention Is All You Need, Vaswani et al, Google Brain, 2017](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/Attention-is-all-you-need-NIPS-2017.pdf)

[Do Vision Transformers See Like Convolutional Neural Networks? M. Raghu, Google Brain, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/Do_Vision_Transformers_See_Like_Convolutional_Neural_Networks_Raghu_GoogleBrain_2021.pdf)

[How Do Vision Transformers Work? N. Park et al, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/How_Do_Vision_Transformers_Work_Park_2022.pdf)

[The Annotated Transformer - delving into Vaswani's paper "Attention Is All You Need", 2018](https://nlp.seas.harvard.edu/annotated-transformer/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/TheAnnotatedTransformer.pdf)

[The Illustrated Transformer, Jay Alamar's blog, 2021](https://jalammar.github.io/illustrated-transformer/)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/TheIllustratedTransformer%E2%80%93JayAlammar%E2%80%93Visualizing_machine_learning_one_concept_at_a_time.pdf)

[The Transformer - Attention Is All You Need - Michal Chromiak's blog, 2017](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/TheTransformer%E2%80%93Attentionisallyouneed-Micha%C5%82Chromiaksblog.pdf)

[Transformers for Image Recognition at Scale, Nel Houlsby and Dirk Weissenborn, Dec 2020, blog](https://blog.research.google/2020/12/transformers-for-image-recognition-at.html)

as pdf [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/Transformers_for_Image_Recognition_at_Scale_blog_2020.pdf)

[An Introduction to Transformers: an NLP Perspective, T. Xiao et al, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/Intro-to-Transformers-Xiao-2023.pdf)

[Transforming Auto-encoders, G. Hinton, A. Krizhevsky, et al., 2011](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/TransformingAutoencodersHinton.pdf)

[Understanding Transformer Reasoning Capabilities via Graph Algorithms, Clayton Sanford et al, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/transformers/Understanding_Transformer_Reasoning_Capabilities_via_Graph_Algorithms_Sanford_2024.pdf)

[Lecture 2 on Transformers from CMU CS 10-423 (GenAI) given in Jan 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/lectures/CMU_GenAI_10-423_2024/lecture2-transformer-ink.pdf)

#### Alternative Architectures to Transformers

[MLP-Mixer: An all-MLP Architecture for Vision, I. Tolstikhin et al, Google, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/mlp_mixers/MLP-Mixer-An_all-MLP_Architecture_for_Vision_Tolstikhin_Google_2021.pdf)

#### Generative models

[Introduction to Diffusion Models for Deep Learning, Ryan O'Connor, 2022 (online blog)](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)

[What are Diffusion Models? Lilian Weng, OpenAI, 2021 (online blog)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)

[Diffusion Models for Video Generation, Lilian Weng, OpenAI, 2024 (online blog)](https://lilianweng.github.io/posts/2024-04-12-diffusion-video/)

[Step-By-Step Diffusion: An Elementary Tutorial, P. Nakkiran et al, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/StepByStepDiffusionAnElementaryTutorial_Nakkiran_2024.pdf)

[Building Diffusion Model's theory from ground up, Ayan Das, ICRL blogposts, 2024](https://iclr-blogposts.github.io/2024/blog/diffusion-theory-from-scratch/)

as a pdf: [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Building_Diffusion_Model_theory_from_ground_up_ICLR_Blogposts_2024.pdf)

[Perspectives on Diffusion, Sander Dieleman, 2023](https://sander.ai/2023/07/20/perspectives.html)

as a pdf: [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Perspectives_on_diffusion%E2%80%93Sander_Dieleman_2023.pdf)

[Interpreting and Improving Diffusion Models from an Optimization Perspective, Frank Permenter et al, Toyota Research Institute, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Interpreting_and_Improving_Diffusion_Models_from_an_Optimization_Perspective_Permenter_2023.pdf)

[Lightweight Diffusion Models: A Survey, W. Song et al, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Lightweight_Diffusion_Models_A_Survey_Song_2024.pdf)

[Flow Matching For Generative Modeling, Y. Lipman et al, Meta AI, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Flow_Matching_for_Generative_Modeling_Lipman_Meta_2023.pdf)

[Generative Modeling by Estimating Gradients of the Data Distribution, Yang Song, Stanford, 2021 (online blog)](https://yang-song.net/blog/2021/score/)

[Deep Unsupervised Learning Using Nonequilibrium Thermodynamics, Jascha Sohl-Dickstein et al, Stanford U., 2015](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Deep_Unsupervised_Learning_using_Nonequilibrium_Thermodynamics_Sohl-Dickstein_2015.pdf)

[Tutorial on Diffusion Models for Imaging and Vision, Stanley Chan, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Tutorial_on_Diffusion_Models_for_Imaging_and_Vision_Chan_2024.pdf)

[On Error Propagation of Diffusion Models, Y. Li, Michaela van der Schaar, U of Cambridge, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/On_Error_Propagation_of_Diffusion_Models_Li_van_der_Schaar_2024.pdf)

[Differential Diffusion: Giving Each Pixel Its Strength, Eran Levin, Ohad Fried, Tel Aviv University, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Differential_Diffusion-Giving_Each_Pixel_Its_Strength_Levin_2024.pdf)

[Consistency Models, Y. Song et al, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Consistency_Models_Song_2023.pdf)

[Understanding Diffusion Models: Unified Perspective, Calvin Luo, Google Brain, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Understanding_Diffusion_Models-A_Unified_Perspective_Luo_GoogleBrain_2022.pdf)

[Diffusion Models Beat GANs on Image Synthesis, Prafulla Dharival, Alex Nichol, OpenAI, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Diffusion_Models_Beat_GANs_on_Image_Synthesis_Dhariwal_2021.pdf)

[Generative Models of Images and Neural Networks, William Smith Peebles, PhD Thesis, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Generative_Models_of_Images_and_Neural_Networks_Peebles_EECS-2023-108.pdf)

[Text-to-image Diffusion Models in Generative AI: A Survey, Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In So Kweon, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Text-to-image_Diffusion_Models_in_Generative_AI-A_Survey_Zhang_2023.pdf)

[Generative Modeling by Estimating Gradients of the Data Distribution, Y. Song et al, Stanford U., 2020](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Generative_Modeling_by_Estimating_Gradients_of_the_Data_Distribution_Song_2020.pdf)

[GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models, Alex Nichol et al, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/GLIDE-Towards_Photorealistic_Image_Generation_and_Editing_with_Text-Guided_Diffusion_Models_Nichol_2021.pdf)

[Denoising Diffusion Probabilistic Models, J. Ho et al, UC Berkeley, 2020](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Denoising_Diffusion_Probabilistic_Models_Ho_UCBerkeley_2020.pdf)

[Denoising Diffusion Implicit Models, J. Song et al, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/denoising_diffusion_implicit_models_Song_Stanford_2021.pdf)

[Improved Techniques for Training Score-Based Generative Models, Y. Song, S. Ermon, 2020](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/Improved_Techniques_for_Training_Score-Based_Generative_Models_Song_2020.pdf)

[Reverse Time Stochastic Differential Equations for Generative Modeling, Ludwig Winkler, 2021](https://ludwigwinkler.github.io/blog/ReverseTimeAnderson/)

[Reverse Time Diffusion Equation Models, Brian DO Anderson, U. of Newcastle, 1980](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/generative_models/ReverseTimeDiffusionEquationModels_Anderson_1982.pdf)

[Lecture 7 on Diffusion Models from CMU CS 10-423 (GenAI) given in Feb 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/lectures/CMU_GenAI_10-423_2024/lecture7-diffusion-ink.pdf)

[Will Diffusion Models Be The Next Frontier of Deep Learning, Devansh, Medium, 2024](https://medium.datadriveninvestor.com/will-diffusion-models-be-the-next-frontier-of-deep-learning-7172bea88581)

#### Variational Inference

[Variational Inference: Foundations and Innovations, David Blei, Columbia U., slides, 2018](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_inference/Blei_Variational_Inference_tutorial_slides_2018.pdf)

[Variational Inference: A Review for Statisticians, David Blei et al, Columbia U., 2018](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_inference/Variational_Inference-A_Review_for_Statisticians_David_Blei_2018.pdf)

[Automatic Variational Inference in Stan, Alp Kucukelbir et al, Columbia U., 2018 ](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_inference/Automatic_Variational_Inference_in_Stan_Kucukelbir_Columbia_2015.pdf)

[Automatic Differentiation Variational Inference, Alp Kucukelbir et al, Columbia U., 2017](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_inference/Automatic_Differentiation_Variational_Inference_Kucukelbir_Columbia_2017.pdf)

[Lecture 8 Diffusion Modeling + Variational Inference from CMU CS 10-423 (GenAI) given in Feb 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/lectures/CMU_GenAI_10-423_2024/lecture8-diffusion-ink.pdf)

Python library containing Variational Inference algorithms such as ADVI : [PyMC](https://github.com/pymc-devs/pymc/tree/main)

#### Variational Autoencoders

[Intuitively Understanding Variational Autoencoders, Irhum Shafkat, Towards Data Science, 2018](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)

as a pdf file [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/Intuitively_Understanding_Variational_Autoencoders_Irhum_Shafkat_TDS.pdf)

[Diffusion Models as a kind of VAE, Angus Turner, 2021, online article](https://angusturner.github.io/generative_models/2021/06/29/diffusion-probabilistic-models-I.html)

[Understanding Variational Autoencoders by Joseph Rocca, Towards Data Science, Sept, 2019](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)

as a pdf file [here](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/Understanding_Variational_Autoencoders_Joseph_Rocca_TowardsDataScience.pdf)

[Variational AutoEncoders (VAE) with PyTorch, Alexander Van de Kleut (online blog)](https://avandekleut.github.io/vae/)

[VAEs in Reinforcement Learning, Nicholsonjm, Medium, 2024](https://medium.com/@nicholsonjm92/vaes-in-reinforcement-learning-932fc2df7026)

related Gym environment: https://gymnasium.farama.org/environments/mujoco/swimmer/

related paper: [Variational State Encoding as Intrinsic Motivation in Reinforcement Learning, Martin Klissarov et al, McGill, ICLR 2019](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/Variational_State_Encoding_as_Intrinsic_Motivation_in_Reinforcement_Learning_Klissarov_McGill_2019.pdf)

[Tutorial on Variational Autoencoders, Carl Doersch, Carnegie Mellon, UC Berkeley, 2021](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/Tutorial_on_Variational_Autoencoders_Doersch_2021.pdf)

[Convolutional Variational Autoencoder with tensorflow, online Tensorflow page](https://www.tensorflow.org/tutorials/generative/cvae)

[Introduction to Variational Autoencoders, Diedrik P. Kingma, Max Welling, 2019](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/An_Introduction_to_Variational_Autoencoders_Kingma_2019.pdf)

[Auto-Encoding Variational Bayes, Diedrik P. Kingma, Max Welling, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/Auto-Encoding_Variational_Bayes_Kingma_2022.pdf)

[The Sparse Autoencoder, Andrew Ng, Lecture Notes CS294A](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/variational_autoencoders/sparseAutoencoder_AndrewNg_LectureNotes.pdf)

[Lecture 9 on Variational Autoencoders from CMU CS 10-423 (GenAI) given in Feb 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/lectures/CMU_GenAI_10-423_2024/lecture9-vae-ink.pdf)


#### The Diffusion Transformer

[Scalable Diffusion Models with Transformers, William Peebles, UC Berkeley, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/diffusion_transformer/Scalable_Diffusion_Models_with_Transformers_Peebles_2022.pdf)

[Masked Diffusion Transformer is a Strong Image Synthesizer, S. Gao et al Sea AI Lab, Nankai U., 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/diffusion_transformer/Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_Gao_ICCV_2023.pdf)

[DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation, S. Mo et al, Huawei, NeurIPS 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/diffusion_transformer/DiT-3D-Exploring_Plain_Diffusion_Transformers_for_3D_Shape_Generation_Mo_NeurIPS_2023.pdf)

[FiT: Flexible Vision Transformer for Diffusion Model, Z. Lu et al, Feb 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/diffusion_transformer/FiT-Flexible_Vision_Transformer_for_Diffusion_Model_Lu_2024.pdf)

[DiffiT: Diffusion Vision Transformers for Image Generation, A. Hatamizadeh et al, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/diffusion_transformer/DiffiT-Diffusion_Vision_Transformers_for_Image_Generation_Hatamizadeh_2023.pdf)

[Diffusion Transformer Explained: Exploring the architecture that brought transformers into image generation, Mario Larcher, Feb 28, 2024](https://towardsdatascience.com/diffusion-transformer-explained-e603c4770f7e)

[Diffusion Transformer (DiT) Models: A Beginner’s Guide, Akruti Acharya, March 18, 2024](https://encord.com/blog/diffusion-models-with-transformers/)

#### Reinforcement Learning from Human Feedback (RLHF) 

[Deep Reinforcement Learnng from Human Preferences, Paul Christiano et al, OpenAI, 2017](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Deep_reinforcement_learning_from_human_preferences_Paul_Christiano_OpenAI_2017.pdf)

[Training Language Models to Follow Instructions With Human Feedback, L. Ouyang et al, OpenAI, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Training_language_models_to_follow_instructions_with_human_feedback_Ouyang_OpenAI_2022.pdf)

[Fine Tuning Language Models from Human Preferences, Daniel M. Ziegler et al, OpenAI, 2020](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Fine-Tuning_Language_Models_from_Human_Preferences_Ziegler_OpenAI_2020.pdf)

[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback, Y. Bai et al, Anthropic, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Training_a_Helpful_and_Harmless_Assistant_with_Reinforcement_Learning_from_Human_Feedback_Bai_Anthropic_2022.pdf)

[Learning to Summarize from Human Feedback, Nisan Stiennon et al, OpenAI, 2022](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Learning_to_summarize_from_human_feedback_Stiennon_OpenAI_2020.pdf)

[Illustrating Reinforcement Learning from Human Feedback (RLHF), Hugging Face article, 2022, Nathan Lambert, Louis Castricato, Leandro von Werra
, Alex Havrilla](https://huggingface.co/blog/rlhf)

[Learning from human preferences, Dario Amodei, OpenAI blog, 2017](https://openai.com/index/learning-from-human-preferences)

[Reinforcement Learning fro Human Feedback, Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)

[A General Theoretical Paradygm to Understand Learning from Human Preferences, M. Azar et al, Google DeepMind, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/A_General_Theoretical_Paradigm_to_Understand_Learning_from_Human_Preferences_Azar_2023.pdf)

[Direct Preference Optimization: Your Language Model is Secretly a Reward Model, Rafel Rafailov et al, Stanford U., 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/Direct_Preference_Optimization-Your_Language_Model_is_Secretly_a_Reward_Model_Rafailov_Stanford_2023.pdf)

[SLiC-HF: Sequence Likelihood Calibration with Human Feedback, Y. Zhao et al, Google Deepmind, 2023](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/SLiC-HF-Sequence_Likelihood_Calibration_with_Human_Feedback_Zhao_Google_2023.pdf)

[KTO: Model Alignment as Prospect Theoretic Optimization, K. Ethayarajh et al, Stanford U., 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/KTO-Model_Alignment_as_Prospect_Theoretic_Optimization_Ethayaragh_2023.pdf)

[ORPO: Monolithic Preference Optimization without Reference Model, Hong, 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/articles/rlhf/ORPO-Monolithic_Preference_Optimization_without_Reference_Model_Hong_2024.pdf)

[Lecture 12 on RLHF from CMU CS 10-423 (GenAI) given in Feb 2024](https://github.com/dimitarpg13/deep_learning_for_image_processing/blob/main/literature/lectures/CMU_GenAI_10-423_2024/lecture12-rlhf-ink.pdf)


### classes, class notes, tutorials and videos

#### Stanford CS231n

[CS231n: Convolutional Neural Networks for Image Recognition: Stanford CS class](https://cs231n.github.io/)

github repo: https://github.com/cs231n/cs231n.github.io

#### CMU CS 10-423

[CMU CS 10-423 GenAI class taught in Jan-Feb 2024](https://www.cs.cmu.edu/~mgormley/courses/10423/)

slides for the class: [slides](https://www.cs.cmu.edu/~mgormley/courses/10423//slides/)

#### MIT 6.S191

[MIT 6.S191: Introduction to Deep Learning, Alexander Amini, years 2020-2023 playlist](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI)

##### 2023

[MIT 6.S191 (2023): Introduction to Deep Learning](https://youtu.be/QDX-1M5Nj7s?si=Qm8KP_zQ6OPxl0Dg)

[MIT 6.S191 (2023): Recurrent Neural Networks, Transformers, and Attention](https://youtu.be/ySEx_Bqxvvo?si=SbIq3k9v5-DLfBkd)

[MIT 6.S191 (2023): Convolutional Neural Networks](https://youtu.be/NmLK_WQBxB4?si=GfN-qRZv6v8khUDQ)

[MIT 6.S191 (2023): Deep Generative Modeling](https://youtu.be/3G5hWM6jqPk?si=6JIf22lq6OZRVRug)

[MIT 6.S191 (2023): Robust and Trustworthy Deep Learning](https://youtu.be/kIiO4VSrivU?si=TYECVR6XdMQCiacD)

[MIT 6.S191 (2023): Reinforcement Learning](https://youtu.be/AhyznRSDjw8?si=7zxmeXOSfMqmZmFt)

[MIT 6.S191 (2023): Deep Learning New Frontiers](https://youtu.be/FHeCmnNe0P8?si=i3hzp5bV8PxsSQPe)

[MIT 6.S191 (2023): Text-to-Image Generation](https://youtu.be/SA-v6Op2kL4?si=5qwJLgj-XQlHrJHx)

[MIT 6.S191 (2023): The Modern Era of Statistics](https://youtu.be/p1NpGC8K-vs?si=FRtxclYFylxYwtvB)

[MIT 6.S191 (2023): The Future of Robot Learning](https://youtu.be/WHvWSYKGMDQ?si=e3MtKxw_20HaLtPm)
